{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "df_covid19 = pd.read_json('https://pomber.github.io/covid19/timeseries.json')\n",
    "df_covid19.head()\n",
    "countries= df_covid19.columns.to_list()\n",
    "\n",
    "def get_countries(countries):\n",
    "    df_world = pd.DataFrame({dt.datetime:None, int:None, int:None, object:None}, \n",
    "                            columns = ['date','confirmed','deaths','recovered', 'country'])\n",
    "\n",
    "    for country in countries:\n",
    "      df_country = pd.json_normalize(df_covid19[str(country)])\n",
    "      df_country['country'] = country\n",
    "      df_world = df_world.append(df_country, ignore_index = True)\n",
    "\n",
    "    df_world['date'] =  pd.to_datetime(df_world['date'] , infer_datetime_format=True)\n",
    "\n",
    "    return df_world\n",
    "\n",
    "df_world = get_countries(countries)\n",
    "df_world.to_csv(\"covid19_200508.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"covid19_200508.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20010"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, _c0: string, _c1: string, _c2: string, _c3: string, _c4: string, _c5: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, item: string, date: string, confirmed: string, deaths: string, recovered: string, country: string]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"covid19_200508.csv\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"covid19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(query, rows=20):\n",
    "    sqlDF = spark.sql(query)\n",
    "    sqlDF.show(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------+------+---------+-------+\n",
      "| item|      date|confirmed|deaths|recovered|country|\n",
      "+-----+----------+---------+------+---------+-------+\n",
      "|10586|2020-05-01|    20739|  1972|    12377| Mexico|\n",
      "|10587|2020-05-02|    22088|  2061|    12377| Mexico|\n",
      "|10588|2020-05-03|    23471|  2154|    13447| Mexico|\n",
      "|10589|2020-05-04|    24905|  2271|    13447| Mexico|\n",
      "|10590|2020-05-05|    26025|  2507|    16810| Mexico|\n",
      "|10591|2020-05-06|    27634|  2704|    17781| Mexico|\n",
      "|10592|2020-05-07|    29616|  2961|    17781| Mexico|\n",
      "+-----+----------+---------+------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "execute_query(\"SELECT * FROM covid19 where country= 'Mexico' and date >= '2020-05-01'\",40) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- item: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- confirmed: string (nullable = true)\n",
      " |-- deaths: string (nullable = true)\n",
      " |-- recovered: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- item: integer (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- confirmed: integer (nullable = true)\n",
      " |-- deaths: integer (nullable = true)\n",
      " |-- recovered: integer (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "df = df.withColumn('item', F.col('item').cast(\"int\"))\n",
    "df = df.withColumn('date', F.col('date').cast(\"date\"))\n",
    "df = df.withColumn('confirmed', F.col('confirmed').cast(\"int\"))\n",
    "df = df.withColumn('deaths', F.col('deaths').cast(\"int\"))\n",
    "df = df.withColumn('recovered', F.col('recovered').cast(\"int\"))\n",
    "df = df.withColumn('country', F.col('country').cast(\"string\"))\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.schema[\"item\"].nullable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"covid19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------+------+---------+-------+----------+----------+\n",
      "| item|      date|confirmed|deaths|recovered|country|    date_1|    date_1|\n",
      "+-----+----------+---------+------+---------+-------+----------+----------+\n",
      "|10586|2020-05-01|    20739|  1972|    12377| Mexico|2020-05-02|2020-04-30|\n",
      "|10587|2020-05-02|    22088|  2061|    12377| Mexico|2020-05-03|2020-05-01|\n",
      "|10588|2020-05-03|    23471|  2154|    13447| Mexico|2020-05-04|2020-05-02|\n",
      "|10589|2020-05-04|    24905|  2271|    13447| Mexico|2020-05-05|2020-05-03|\n",
      "|10590|2020-05-05|    26025|  2507|    16810| Mexico|2020-05-06|2020-05-04|\n",
      "|10591|2020-05-06|    27634|  2704|    17781| Mexico|2020-05-07|2020-05-05|\n",
      "|10592|2020-05-07|    29616|  2961|    17781| Mexico|2020-05-08|2020-05-06|\n",
      "+-----+----------+---------+------+---------+-------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "execute_query(\"\"\"\n",
    "              SELECT a.*, \n",
    "                  date_add(date, 1) as date_1,\n",
    "                  date_sub(date, 1) as date_1\n",
    "              FROM covid19 a where a.country= 'Mexico' and date >= '2020-05-01'\n",
    "              \"\"\",40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-----------+--------+-----------+-----------+--------+-----------+----------+----------+\n",
      "|item_a|item_b|confirmed_a|deaths_a|recovered_a|confirmed_b|deaths_b|recovered_b|    date_a|    date_b|\n",
      "+------+------+-----------+--------+-----------+-----------+--------+-----------+----------+----------+\n",
      "| 10586| 10585|      20739|    1972|      12377|      19224|    1859|      11423|2020-05-01|2020-04-30|\n",
      "| 10587| 10586|      22088|    2061|      12377|      20739|    1972|      12377|2020-05-02|2020-05-01|\n",
      "| 10588| 10587|      23471|    2154|      13447|      22088|    2061|      12377|2020-05-03|2020-05-02|\n",
      "| 10589| 10588|      24905|    2271|      13447|      23471|    2154|      13447|2020-05-04|2020-05-03|\n",
      "| 10590| 10589|      26025|    2507|      16810|      24905|    2271|      13447|2020-05-05|2020-05-04|\n",
      "| 10591| 10590|      27634|    2704|      17781|      26025|    2507|      16810|2020-05-06|2020-05-05|\n",
      "| 10592| 10591|      29616|    2961|      17781|      27634|    2704|      17781|2020-05-07|2020-05-06|\n",
      "+------+------+-----------+--------+-----------+-----------+--------+-----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "execute_query(\"\"\"\n",
    "              SELECT \n",
    "                  a.item as item_a,\n",
    "                  b.item as item_b,\n",
    "                  a.confirmed as confirmed_a, \n",
    "                  a.deaths as deaths_a, \n",
    "                  a.recovered as recovered_a,\n",
    "                  b.confirmed as confirmed_b, \n",
    "                  b.deaths as deaths_b, \n",
    "                  b.recovered as recovered_b,\n",
    "                  a.date as date_a,\n",
    "                  b.date as date_b\n",
    "              FROM covid19 a \n",
    "              inner join covid19 b on a.country = b.country and a.date = date_add(b.date, 1)\n",
    "              where a.country= 'Mexico' and a.date >= '2020-05-01'\n",
    "              \"\"\",40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|  country|max_confirmed|\n",
      "+---------+-------------+\n",
      "|   Brazil|       135773|\n",
      "|     Peru|        58526|\n",
      "|  Ecuador|        31881|\n",
      "|   Mexico|        29616|\n",
      "|    Chile|        24581|\n",
      "| Colombia|         9456|\n",
      "|Argentina|         5371|\n",
      "|  Bolivia|         2081|\n",
      "|  Uruguay|          684|\n",
      "| Paraguay|          462|\n",
      "|Venezuela|          381|\n",
      "+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "execute_query(\"\"\"\n",
    "              SELECT country, max(confirmed) as max_confirmed\n",
    "              FROM covid19 a \n",
    "              where a.country in ('Mexico', 'Peru', 'Colombia', 'Chile', 'Ecuador', 'Bolivia', 'Venezuela', 'Argentina', 'Brazil', 'Uruguay', 'Paraguay')\n",
    "              group by country\n",
    "              order by 2 desc\n",
    "              \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|    country|confirmed|\n",
      "+-----------+---------+\n",
      "|El Salvador|      695|\n",
      "+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "execute_query(\"\"\"\n",
    "              SELECT country, confirmed\n",
    "              FROM covid19 a\n",
    "              where date = '2020-05-07'\n",
    "              and country like '%Sal%'\n",
    "              order by 2 desc\n",
    "              \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def its_america(value):\n",
    "   if value in ['Peru', 'Colombia', 'Chile', 'Ecuador', 'Bolivia', 'Venezuela', 'Argentina', 'Brazil', 'Uruguay', 'Paraguay']:\n",
    "        return 'SurAmerica'\n",
    "   elif value in ['Guatemala','El Salvador','Panama', 'Costa Rica', 'Puerto Rico']: \n",
    "        return 'CentroAmerica'\n",
    "   elif value in ['Canada','US','Mexico']: \n",
    "        return 'NorteAmerica'\n",
    "   else: \n",
    "        return 'na'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NorteAmerica'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "its_america('Mexico')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---------+------+---------+-----------+-----------+\n",
      "|item|      date|confirmed|deaths|recovered|    country|its_america|\n",
      "+----+----------+---------+------+---------+-----------+-----------+\n",
      "|   0|2020-01-22|        0|     0|        0|Afghanistan|         na|\n",
      "|   1|2020-01-23|        0|     0|        0|Afghanistan|         na|\n",
      "|   2|2020-01-24|        0|     0|        0|Afghanistan|         na|\n",
      "|   3|2020-01-25|        0|     0|        0|Afghanistan|         na|\n",
      "|   4|2020-01-26|        0|     0|        0|Afghanistan|         na|\n",
      "|   5|2020-01-27|        0|     0|        0|Afghanistan|         na|\n",
      "|   6|2020-01-28|        0|     0|        0|Afghanistan|         na|\n",
      "|   7|2020-01-29|        0|     0|        0|Afghanistan|         na|\n",
      "|   8|2020-01-30|        0|     0|        0|Afghanistan|         na|\n",
      "|   9|2020-01-31|        0|     0|        0|Afghanistan|         na|\n",
      "|  10|2020-02-01|        0|     0|        0|Afghanistan|         na|\n",
      "|  11|2020-02-02|        0|     0|        0|Afghanistan|         na|\n",
      "|  12|2020-02-03|        0|     0|        0|Afghanistan|         na|\n",
      "|  13|2020-02-04|        0|     0|        0|Afghanistan|         na|\n",
      "|  14|2020-02-05|        0|     0|        0|Afghanistan|         na|\n",
      "|  15|2020-02-06|        0|     0|        0|Afghanistan|         na|\n",
      "|  16|2020-02-07|        0|     0|        0|Afghanistan|         na|\n",
      "|  17|2020-02-08|        0|     0|        0|Afghanistan|         na|\n",
      "|  18|2020-02-09|        0|     0|        0|Afghanistan|         na|\n",
      "|  19|2020-02-10|        0|     0|        0|Afghanistan|         na|\n",
      "+----+----------+---------+------+---------+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "udf_its_america = udf(its_america, StringType())\n",
    "df_with_america = df.withColumn(\"its_america\", udf_its_america(F.col('country')))\n",
    "df_with_america.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_america.createOrReplaceTempView(\"covid19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "|        |  covid19|       true|\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "execute_query(\"show tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|databaseName|\n",
      "+------------+\n",
      "|     default|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "execute_query(\"show databases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------+\n",
      "|   col_name|data_type|comment|\n",
      "+-----------+---------+-------+\n",
      "|       item|      int|   null|\n",
      "|       date|     date|   null|\n",
      "|  confirmed|      int|   null|\n",
      "|     deaths|      int|   null|\n",
      "|  recovered|      int|   null|\n",
      "|    country|   string|   null|\n",
      "|its_america|   string|   null|\n",
      "+-----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "execute_query(\"describe covid19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+------------+\n",
      "|       country|confirmed| its_america|\n",
      "+--------------+---------+------------+\n",
      "|            US|  1257023|NorteAmerica|\n",
      "|         Spain|   221447|          na|\n",
      "|         Italy|   215858|          na|\n",
      "|United Kingdom|   207977|          na|\n",
      "|        Russia|   177160|          na|\n",
      "|        France|   174918|          na|\n",
      "|       Germany|   169430|          na|\n",
      "|        Brazil|   135773|  SurAmerica|\n",
      "|        Turkey|   133721|          na|\n",
      "|          Iran|   103135|          na|\n",
      "|         China|    83975|          na|\n",
      "|        Canada|    66201|NorteAmerica|\n",
      "|          Peru|    58526|  SurAmerica|\n",
      "|         India|    56351|          na|\n",
      "|       Belgium|    51420|          na|\n",
      "|   Netherlands|    41973|          na|\n",
      "|  Saudi Arabia|    33731|          na|\n",
      "|       Ecuador|    30298|  SurAmerica|\n",
      "|   Switzerland|    30126|          na|\n",
      "|        Mexico|    29616|NorteAmerica|\n",
      "+--------------+---------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "execute_query(\"\"\"\n",
    "              SELECT country, confirmed, its_america\n",
    "              FROM covid19 a\n",
    "              where date = '2020-05-07'\n",
    "              and its_america != 'n/a'\n",
    "              order by 2 desc\n",
    "              \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bucketing, Sorting and Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la fuente de datos basada en archivos, también es posible agrupar y ordenar o particionar la salida. El agrupamiento y la clasificación solo se aplican a las tablas persistentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spark.sql(\"drop table covid19_bucketed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_america.write.bucketBy(10, \"country\").sortBy(\"confirmed\").saveAsTable(\"covid19_bucketed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+\n",
      "|       country|confirmed|\n",
      "+--------------+---------+\n",
      "|            US|  1257023|\n",
      "|         Spain|   221447|\n",
      "|         Italy|   215858|\n",
      "|United Kingdom|   207977|\n",
      "|        Russia|   177160|\n",
      "|        France|   174918|\n",
      "|       Germany|   169430|\n",
      "|        Brazil|   135773|\n",
      "|        Turkey|   133721|\n",
      "|          Iran|   103135|\n",
      "|         China|    83975|\n",
      "|        Canada|    66201|\n",
      "|          Peru|    58526|\n",
      "|         India|    56351|\n",
      "|       Belgium|    51420|\n",
      "|   Netherlands|    41973|\n",
      "|  Saudi Arabia|    33731|\n",
      "|       Ecuador|    30298|\n",
      "|   Switzerland|    30126|\n",
      "|        Mexico|    29616|\n",
      "+--------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "execute_query(\"\"\"\n",
    "              SELECT country, confirmed\n",
    "              FROM covid19_bucketed a\n",
    "              where date = '2020-05-07'\n",
    "              order by 2 desc\n",
    "              \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mientras que la partición se puede usar con save y saveAsTable cuando se usan las API de conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_america.write.partitionBy(\"its_america\").format(\"parquet\").save(\"covid19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet = spark.read.parquet(\"./covid19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, item: string, confirmed: string, deaths: string, recovered: string, country: string, its_america: string]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_parquet.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reference\n",
    "\n",
    "- Python:  https://github.com/jakevdp/PythonDataScienceHandbook\n",
    "- Hive: https://github.com/vavasquezhe/apache-hive-course\n",
    "- SparkSQL: https://spark.apache.org/docs/2.4.0/sql-getting-started.html\n",
    "- Databricks: https://docs.databricks.com/spark/latest/spark-sql/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
